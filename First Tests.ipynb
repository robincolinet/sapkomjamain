{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, ConcatDataset\n",
    "from torchvision import datasets, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_dossier_images = \"./data\"\n",
    "chemin_dossier_images_affiche = \"./data/DAM\"\n",
    "chemin_test = \"./data/test_image_headmind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cr√©e une class custom pour labelliser nos images\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(folder_path, img_name) for img_name in os.listdir(folder_path)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # On utilise le titre de l'image comme label\n",
    "        label = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image loading and feature extraction\n",
    "def extract_features(image_folder_path, model, transform=None):\n",
    "    dataset = CustomDataset(image_folder_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, label in dataloader:\n",
    "            features = model(images)\n",
    "            features = features.cpu().numpy().flatten()\n",
    "            features_list.append((features,label))\n",
    "\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset of features extracted from training images\n",
    "def create_train_dataset_features(image_folder_path, model, nb_transformation_per_image, transform=None):\n",
    "    features_list = []\n",
    "    for _ in range(nb_transformation_per_image):\n",
    "        features_list.extend(extract_features(image_folder_path, model, transform))\n",
    "\n",
    "    all_features = np.array([features for features, _ in features_list])\n",
    "    all_labels = np.array([label for _, label in features_list])\n",
    "\n",
    "    # all_features_tensor = torch.tensor(all_features)\n",
    "    # all_labels_tensor = torch.tensor(all_labels)\n",
    "\n",
    "    # return DataLoader(TensorDataset(all_features_tensor, all_labels), batch_size=1, shuffle=True)\n",
    "    return all_features, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "# Image folder path\n",
    "image_folder_path = 'data/DAM_extraction/'\n",
    "\n",
    "# Transformation applied to each image\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    #transforms.RandomErasing(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Number of transformation used by image\n",
    "nb_transformation_per_image = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_data_set = create_train_dataset_features(image_folder_path, model, nb_transformation_per_image ,transform=train_transform)\n",
    "# torch.save(train_dataloader,'train_dataloader.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity between two feature vectors\n",
    "def calculate_cosine_similarity(feature1, feature2):\n",
    "    # Ensure the features are 1D tensors\n",
    "    feature1 = feature1.flatten()\n",
    "    feature2 = feature2.flatten()\n",
    "\n",
    "    # # Convert tensors to numpy arrays\n",
    "    # feature1_np = feature1.cpu().numpy()\n",
    "    # feature2_np = feature2.cpu().numpy()\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity([feature1], [feature2])[0, 0]\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similar_images(input_image_path, features_dataloader, model, preprocess, top_k=10):\n",
    "    # Load the input image\n",
    "    input_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "\n",
    "    # Preprocess the input image\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Extract features for the input image\n",
    "    with torch.no_grad():\n",
    "        input_features = np.array(model(input_batch).cpu().numpy().flatten())\n",
    "\n",
    "    # Calculate cosine similarity with the features in the features_dataloader\n",
    "    similarities = []\n",
    "    all_features, all_labels = features_dataloader\n",
    "    for features, _ in zip(all_features, all_labels):\n",
    "        similarity = calculate_cosine_similarity(input_features, features)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    # Get indices of top-k similar images\n",
    "    top_k_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:top_k]\n",
    "\n",
    "    # Return the top-k similar images\n",
    "    top_k_similar_images = [(features[i], label) for i, (features, label) in enumerate(zip(all_features, all_labels)) if i in top_k_indices]\n",
    "\n",
    "    return top_k_similar_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img,label):\n",
    "    img = img / 2 + 0.5 \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label to find is : 02JHE090I610C905\n",
      "The top 10 similar images are :\n",
      "['02MDA070I600C417']\n",
      "['02JHE090I610C905']\n",
      "['02JHE090I610C905']\n",
      "['02MDA070I600C417']\n",
      "['01DJW924I132C976']\n",
      "['02MDA070I600C417']\n",
      "['02JHE090I610C905']\n",
      "['02MDA070I600C417']\n",
      "['01DJW924I132C976']\n",
      "['02JHE090I610C905']\n"
     ]
    }
   ],
   "source": [
    "input_image_path = \"data/DAM/02JHE090I610C905.jpeg\"\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "top_10 = get_top_similar_images(input_image_path, extracted_features_data_set, model, preprocess, top_k=10)\n",
    "\n",
    "print(\"The label to find is : 02JHE090I610C905\")\n",
    "# imshow(Image.open(input_image_path).convert(\"RGB\"),\"02JHE090I610C905\")\n",
    "\n",
    "print(\"The top 10 similar images are :\")\n",
    "for _ , label in top_10:\n",
    "    # image_path = \"data/DAM/\"+label+\".jpeg\"\n",
    "    # image = Image.open(image_path).convert(\"RGB\")\n",
    "    # imshow(image,label)\n",
    "    print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model.eval()\n",
    "\n",
    "# image_path = 'data/DAM/010M03A1116X9000.jpeg'\n",
    "# input_image = Image.open(image_path)\n",
    "\n",
    "image_paths = [\n",
    "\t'data/DAM/012B03A3985X5902.jpeg',\n",
    "\t'data/DAM/012A09A3232X5597.jpeg',\n",
    "\t'data/DAM/14DDN978A133C568.jpeg'\n",
    "]\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Extract features for each image\n",
    "features_list = []\n",
    "for image_path in image_paths:\n",
    "    input_image = Image.open(image_path)\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = model(input_batch)\n",
    "\n",
    "    # Convert features to a numpy array and flatten it\n",
    "    features_list.append(features.cpu().numpy().flatten())\n",
    "\n",
    "# Compute cosine similarity between features\n",
    "cosine_similarities = cosine_similarity(features_list)\n",
    "\n",
    "# Print the cosine similarity matrix\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(cosine_similarities)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"# Path to the DAM image for comparison\n",
    "query_image_path = 'data/DAM/012B03A3985X5902.jpeg'\n",
    "\n",
    "# Path to the data folder\n",
    "data_folder = 'data'\n",
    "\n",
    "# Number of top similar images to retrieve\n",
    "top_k = 10\n",
    "\n",
    "# Load and preprocess the query image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "query_image = Image.open(query_image_path)\n",
    "query_tensor = preprocess(query_image)\n",
    "query_batch = query_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "with torch.no_grad():\n",
    "    query_features = model(query_batch)\n",
    "\n",
    "\n",
    "# Calculate cosine similarity with all other images in the DAM folder\n",
    "similarities = []\n",
    "image_paths = []\n",
    "\n",
    "dam_folder = os.path.join(data_folder, 'DAM')\n",
    "\n",
    "for filename in os.listdir(dam_folder):\n",
    "    if filename.endswith('.jpeg'):\n",
    "        image_path = os.path.join(dam_folder, filename)\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        input_image = Image.open(image_path)\n",
    "        input_tensor = preprocess(input_image)\n",
    "        input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = model(input_batch)\n",
    "\n",
    "        # Calculate cosine similarity with the query image\n",
    "        similarity = calculate_cosine_similarity(query_features, features)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "# Get indices of top-k similar images\n",
    "top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "\n",
    "# Display the query image\n",
    "plt.subplot(1, top_k + 1, 1)\n",
    "plt.imshow(query_image)\n",
    "plt.title('Query Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the top-k similar images\n",
    "for i, index in enumerate(top_indices):\n",
    "    image_path = image_paths[index]\n",
    "    similar_image = Image.open(image_path)\n",
    "\n",
    "    plt.subplot(1, top_k + 1, i + 2)\n",
    "    plt.imshow(similar_image)\n",
    "    plt.title(f'Top-{i + 1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89hdk3d7N-hb"
      },
      "source": [
        "##### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYNno0xtOFJ-"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-research/simclr/blob/master/colabs/finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9oIl-rCOypT"
      },
      "source": [
        "## SimCLR: A Simple Framework for Contrastive Learning of Visual Representations\n",
        "\n",
        "This colab demonstrates how to load pretrained/finetuned SimCLR models from hub modules for fine-tuning\n",
        "\n",
        "The checkpoints are accessible in the following Google Cloud Storage folders.\n",
        "\n",
        "* Pretrained SimCLRv2 models with a linear classifier: [gs://simclr-checkpoints/simclrv2/pretrained](https://console.cloud.google.com/storage/browser/simclr-checkpoints/simclrv2/pretrained)\n",
        "* Fine-tuned SimCLRv2 models on 1% of labels: [gs://simclr-checkpoints/simclrv2/finetuned_1pct](https://console.cloud.google.com/storage/browser/simclr-checkpoints/simclrv2/finetuned_1pct)\n",
        "* Fine-tuned SimCLRv2 models on 10% of labels: [gs://simclr-checkpoints/simclrv2/finetuned_10pct](https://console.cloud.google.com/storage/browser/simclr-checkpoints/simclrv2/finetuned_10pct)\n",
        "* Fine-tuned SimCLRv2 models on 100% of labels: [gs://simclr-checkpoints/simclrv2/finetuned_100pct](https://console.cloud.google.com/storage/browser/simclr-checkpoints/simclrv2/finetuned_100pct)\n",
        "* Supervised models with the same architectures: [gs://simclr-checkpoints/simclrv2/pretrained](https://console.cloud.google.com/storage/browser/simclr-checkpoints/simclrv2/pretrained)\n",
        "\n",
        "Use the corresponding checkpoint / hub-module paths for accessing the model. For example, to use a pre-trained model (with a linear classifier) with ResNet-152 (2x+SK), set the path to `gs://simclr-checkpoints/simclrv2/pretrained/r152_2x_sk1`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installations & imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (2.9.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.6.3)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\python310\\lib\\site-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\python310\\lib\\site-packages (from tensorflow) (1.23.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (21.3)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
            "     -------------------------------------- 895.7/895.7 kB 2.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from tensorflow) (58.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python310\\lib\\site-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\python310\\lib\\site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\python310\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python310\\lib\\site-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.9.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "     -------------------------------------- 438.7/438.7 kB 3.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.30.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.5.26\n",
            "    Uninstalling flatbuffers-23.5.26:\n",
            "      Successfully uninstalled flatbuffers-23.5.26\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed flatbuffers-1.12 protobuf-3.19.6 tensorboard-data-server-0.6.1 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.50.0 requires protobuf>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.3 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tfds-nightly 4.9.3.dev202312061310 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_hub in c:\\python310\\lib\\site-packages (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\python310\\lib\\site-packages (from tensorflow_hub) (1.23.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in c:\\python310\\lib\\site-packages (from tensorflow_hub) (3.19.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in c:\\python310\\lib\\site-packages (4.9.3)\n",
            "Requirement already satisfied: absl-py in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: array-record in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (0.4.1)\n",
            "Requirement already satisfied: click in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow_datasets) (8.1.3)\n",
            "Requirement already satisfied: dm-tree in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: etils>=0.9.0 in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (1.5.2)\n",
            "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (1.23.1)\n",
            "Requirement already satisfied: promise in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
            "Collecting protobuf>=3.20 (from tensorflow_datasets)\n",
            "  Downloading protobuf-4.25.1-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: psutil in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (5.9.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (2.30.0)\n",
            "Requirement already satisfied: tensorflow-metadata in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: toml in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (4.64.0)\n",
            "Requirement already satisfied: wrapt in c:\\python310\\lib\\site-packages (from tensorflow_datasets) (1.14.1)\n",
            "Requirement already satisfied: fsspec in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2022.11.0)\n",
            "Requirement already satisfied: importlib_resources in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.1.1)\n",
            "Requirement already satisfied: typing_extensions in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.7.1)\n",
            "Requirement already satisfied: zipp in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.6.15)\n",
            "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from click->tensorflow_datasets) (0.4.5)\n",
            "Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\python310\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.57.0)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
            "     -------------------------------------- 904.0/904.0 kB 1.5 MB/s eta 0:00:00\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "Successfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.50.0 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "ERROR: Could not find a version that satisfies the requirement ressource (from versions: none)\n",
            "ERROR: No matching distribution found for ressource\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tfds-nightly in c:\\python310\\lib\\site-packages (4.9.3.dev202312061310)\n",
            "Requirement already satisfied: absl-py in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied: click in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tfds-nightly) (8.1.3)\n",
            "Requirement already satisfied: dm-tree in c:\\python310\\lib\\site-packages (from tfds-nightly) (0.1.8)\n",
            "Requirement already satisfied: etils>=0.9.0 in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly) (1.5.2)\n",
            "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from tfds-nightly) (1.23.1)\n",
            "Requirement already satisfied: promise in c:\\python310\\lib\\site-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in c:\\python310\\lib\\site-packages (from tfds-nightly) (3.20.3)\n",
            "Requirement already satisfied: psutil in c:\\python310\\lib\\site-packages (from tfds-nightly) (5.9.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\python310\\lib\\site-packages (from tfds-nightly) (2.30.0)\n",
            "Requirement already satisfied: tensorflow-metadata in c:\\python310\\lib\\site-packages (from tfds-nightly) (1.14.0)\n",
            "Requirement already satisfied: termcolor in c:\\python310\\lib\\site-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied: toml in c:\\python310\\lib\\site-packages (from tfds-nightly) (0.10.2)\n",
            "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from tfds-nightly) (4.64.0)\n",
            "Requirement already satisfied: wrapt in c:\\python310\\lib\\site-packages (from tfds-nightly) (1.14.1)\n",
            "Requirement already satisfied: fsspec in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly) (2022.11.0)\n",
            "Requirement already satisfied: importlib_resources in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly) (6.1.1)\n",
            "Requirement already satisfied: typing_extensions in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly) (4.7.1)\n",
            "Requirement already satisfied: zipp in c:\\python310\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly) (3.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->tfds-nightly) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->tfds-nightly) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->tfds-nightly) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.19.0->tfds-nightly) (2022.6.15)\n",
            "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from click->tfds-nightly) (0.4.5)\n",
            "Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from promise->tfds-nightly) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\python310\\lib\\site-packages (from tensorflow-metadata->tfds-nightly) (1.57.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow\n",
        "! pip install tensorflow_hub\n",
        "! pip install tensorflow_datasets\n",
        "! pip install ressource\n",
        "! pip install tfds-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ih5NlvdDEOI1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.enable_eager_execution()\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "W Bags           830\n",
              "W RTW            627\n",
              "W Accessories    543\n",
              "W Shoes          336\n",
              "W SLG            302\n",
              "Watches          129\n",
              "Name: Product_BusinessUnitDesc, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "references = pd.read_csv('data/product_list.csv')\n",
        "references[\"Product_BusinessUnitDesc\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnyvq6g-P2rW",
        "outputId": "188824cb-d7dc-44d1-d564-a7128159000e"
      },
      "outputs": [],
      "source": [
        "#@title Load class id to label text mapping from big_transfer (hidden)\n",
        "# Code snippet credit: https://github.com/google-research/big_transfer\n",
        "\n",
        "\n",
        "\n",
        "int_to_mmc = {}\n",
        "mmc_to_int = {}\n",
        "\n",
        "for i, classe in enumerate(references[\"MMC\"]):\n",
        "  int_to_mmc.update({i: classe})\n",
        "  mmc_to_int.update({classe : i})\n",
        "\n",
        "# tf_flowers_labels = ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss8CFQBCU-Pr",
        "outputId": "45a7bfc5-730d-42d7-a23e-338616017d11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '010M03A1116X9000',\n",
              " 1: '010M09A1101X0863',\n",
              " 2: '010M27A0006X0200',\n",
              " 3: '011A11A1166X4150',\n",
              " 4: '011A11A1166X9000',\n",
              " 5: '011B13A6014X0200',\n",
              " 6: '011B48A3874X0863',\n",
              " 7: '011D01A1166X5645',\n",
              " 8: '011D01A1166X9000',\n",
              " 9: '011D02A1166X3250',\n",
              " 10: '011G05ACMIXX0863',\n",
              " 11: '011G07A1166X9000',\n",
              " 12: '011G12A1166X4150',\n",
              " 13: '011G13A1212X0200',\n",
              " 14: '011J12A1166X9000',\n",
              " 15: '011J22X8801X9000',\n",
              " 16: '011J50A8976X9632',\n",
              " 17: '011P11A1166X9000',\n",
              " 18: '011P12A3862X0863',\n",
              " 19: '011P34A1166X5435',\n",
              " 20: '011R33A7970X9639',\n",
              " 21: '011R68A1212X4150',\n",
              " 22: '011R70A1166X9000',\n",
              " 23: '011V41A3062X5435',\n",
              " 24: '012A09A3232X5597',\n",
              " 25: '012B03A3985X5902',\n",
              " 26: '012J03A3236X0835',\n",
              " 27: '013L02A4006X5435',\n",
              " 28: '013T03WC437X9663',\n",
              " 29: '013T05TU430X0854',\n",
              " 30: '014C10AM034X1705',\n",
              " 31: '014E01CM514X0863',\n",
              " 32: '014E20CM514X0863',\n",
              " 33: '014E20TU507X0850',\n",
              " 34: '014P02AM042X5800',\n",
              " 35: '014S26AM028X2847',\n",
              " 36: '014S52AM044X9650',\n",
              " 37: '014S52WC029X0863',\n",
              " 38: '014S55AM042X0820',\n",
              " 39: '014S58AM304X0200',\n",
              " 40: '014S59AM005X4220',\n",
              " 41: '014S62TM033X5902',\n",
              " 42: '014S73AM105X4235',\n",
              " 43: '014S92AM032X0863',\n",
              " 44: '015R30AL030X9000',\n",
              " 45: '015V02WL220X8265',\n",
              " 46: '017M44A2960X9000',\n",
              " 47: '017V55A2960X6830',\n",
              " 48: '01BB01A2102X4847',\n",
              " 49: '021B18A8765X4150',\n",
              " 50: '021B39A6009X4217',\n",
              " 51: '021B39A7018X5840',\n",
              " 52: '021E04A7722X1851',\n",
              " 53: '021J12A8676X9366',\n",
              " 54: '021J21A8680X9381',\n",
              " 55: '021J50A7109X5830',\n",
              " 56: '021L11A6724X9376',\n",
              " 57: '021L35ADMIXX0200',\n",
              " 58: '021P05A9718X9611',\n",
              " 59: '021P38A6560X9654',\n",
              " 60: '021R11A8676X9366',\n",
              " 61: '021R14A1212X0200',\n",
              " 62: '021R14A1212X9000',\n",
              " 63: '021R26A6724X9376',\n",
              " 64: '021R26ADMIXX0200',\n",
              " 65: '021R33X8808X9000',\n",
              " 66: '021R36X8808X9000',\n",
              " 67: '021R53A7722X1851',\n",
              " 68: '021R63A1166X4150',\n",
              " 69: '021R63A1166X8270',\n",
              " 70: '021R63A1166X9000',\n",
              " 71: '021R71A8677X0845',\n",
              " 72: '021R86A3836X9645',\n",
              " 73: '021V26A3360X9305',\n",
              " 74: '022P01A3154X9374',\n",
              " 75: '022P24A3328X4220',\n",
              " 76: '023T03TC443X9605',\n",
              " 77: '023T05A4430X0858',\n",
              " 78: '024E63AM308X9641',\n",
              " 79: '024G03TM110X1660',\n",
              " 80: '024S14TM014X9654',\n",
              " 81: '024S26JG007X0875',\n",
              " 82: '024S35TM110X8270',\n",
              " 83: '027C10A2826X5882',\n",
              " 84: '027C18A2961X0100',\n",
              " 85: '027J19A3339X8270',\n",
              " 86: '040M25A1113X1832',\n",
              " 87: '040M25A1113X5871',\n",
              " 88: '040M36A1116X1402',\n",
              " 89: '040V23A1113X1832',\n",
              " 90: '041B19A6009X9000',\n",
              " 91: '041B22A1212X9000',\n",
              " 92: '041B24A1212X9000',\n",
              " 93: '041B27A6130X5609',\n",
              " 94: '041B27A6170X0882',\n",
              " 95: '041B27A6170X8882',\n",
              " 96: '041B54A6740X1864',\n",
              " 97: '041G03A1087X9330',\n",
              " 98: '041L10X8808X5900',\n",
              " 99: '041L15A2006X5640',\n",
              " 100: '041P41A1184X5871',\n",
              " 101: '041R05A1166X5645',\n",
              " 102: '041R06A1212X4150',\n",
              " 103: '041R09A8788X0200',\n",
              " 104: '041R21A7631X1852',\n",
              " 105: '041R37A1262X6824',\n",
              " 106: '041R39A1212X3250',\n",
              " 107: '041R39A1212X4150',\n",
              " 108: '041V17A1087X9330',\n",
              " 109: '042J04A3159X6642',\n",
              " 110: '042R01A3330X5701',\n",
              " 111: '043T03CP450X0800',\n",
              " 112: '043T03CP451X5882',\n",
              " 113: '043T03PB451X5882',\n",
              " 114: '044E20BD507X0854',\n",
              " 115: '044E20CA504X0150',\n",
              " 116: '044E20CN504X0150',\n",
              " 117: '044E20MO517X5830',\n",
              " 118: '044G11AM507X9609',\n",
              " 119: '044G11AM507X9656',\n",
              " 120: '044G22AM115X1350',\n",
              " 121: '044R01AM314X1832',\n",
              " 122: '044S27AM703X9000',\n",
              " 123: '044S51AM707X5882',\n",
              " 124: '044S51BD713X0849',\n",
              " 125: '044S51CA713X0849',\n",
              " 126: '044S51CN713X0849',\n",
              " 127: '044S51CN713X0858',\n",
              " 128: '044S51FM713X0849',\n",
              " 129: '044S51PC713X0849',\n",
              " 130: '044S60AM018X0861',\n",
              " 131: '044S68AM019X0200',\n",
              " 132: '044S78MO504X0150',\n",
              " 133: '044S97BD603X0854',\n",
              " 134: '044S97PB603X0858',\n",
              " 135: '044S97PC603X0849',\n",
              " 136: '044T04AM507X9609',\n",
              " 137: '044T16AM019X9000',\n",
              " 138: '044W02AM507X9608',\n",
              " 139: '046C78CF010X5460',\n",
              " 140: '047C09A2860X6824',\n",
              " 141: '047C10A2852X8845',\n",
              " 142: '047C16A6818X1867',\n",
              " 143: '047G10A3905X1320',\n",
              " 144: '047J44A3343X5830',\n",
              " 145: '048V98AL830X9000',\n",
              " 146: '04BP01A2840X9608',\n",
              " 147: '04BS01A2840X9608',\n",
              " 148: '050M07S1294X9000',\n",
              " 149: '050M09A1285X8806',\n",
              " 150: '051B46A7020X5840',\n",
              " 151: '051J32A1238X9330',\n",
              " 152: '051J59A3758X5898',\n",
              " 153: '051L38A1242X8806',\n",
              " 154: '051P45A1290X7812',\n",
              " 155: '051V05A1284X7817',\n",
              " 156: '051V20A1166X0200',\n",
              " 157: '054E01AM521X3829',\n",
              " 158: '054G12AM055X5820',\n",
              " 159: '054G30AM115X9000',\n",
              " 160: '054L03AM605X9000',\n",
              " 161: '054S12AM017X8803',\n",
              " 162: '054S51AM716X0856',\n",
              " 163: '054S63AM115X0200',\n",
              " 164: '054S76AM029X9000',\n",
              " 165: '054T41AM703X9000',\n",
              " 166: '055P98AL100X9000',\n",
              " 167: '055V22AL005X9000',\n",
              " 168: '056G18AF010X0201',\n",
              " 169: '056M42AF003X9000',\n",
              " 170: '057C19A1116X5640',\n",
              " 171: '057P21A2821X5898',\n",
              " 172: '110M36A1384X0888',\n",
              " 173: '111B18X8808X9900',\n",
              " 174: '111B54A3780X9609',\n",
              " 175: '111J14A7780X0300',\n",
              " 176: '111J15A3887X0888',\n",
              " 177: '111J40A8505X9000',\n",
              " 178: '111J51A1212X9000',\n",
              " 179: '111J60Y8808X8120',\n",
              " 180: '111J64A8505X0300',\n",
              " 181: '111P38A6805X0861',\n",
              " 182: '111P51A7771X9330',\n",
              " 183: '111R17A1166X4150',\n",
              " 184: '111V03A7762X8402',\n",
              " 185: '111V17A7763X1813',\n",
              " 186: '111V29A6805X0858',\n",
              " 187: '111V29A6805X1821',\n",
              " 188: '111V33A6805X0817',\n",
              " 189: '111V35A6805X1821',\n",
              " 190: '112E01A3341X5651',\n",
              " 191: '112J06A3941X5817',\n",
              " 192: '112V19A3940X5817',\n",
              " 193: '113S04A4013X8851',\n",
              " 194: '113T03RL464X0200',\n",
              " 195: '114E47AM726X5803',\n",
              " 196: '114E82AM722X0200',\n",
              " 197: '114L08AM703X0200',\n",
              " 198: '114P17AM035X9330',\n",
              " 199: '114S27AM115X9000',\n",
              " 200: '114S48AM725X5802',\n",
              " 201: '114S51AM716X5882',\n",
              " 202: '114S55AM150X9406',\n",
              " 203: '114T26AM703X9000',\n",
              " 204: '115B22XL029X9665',\n",
              " 205: '115B30AL113X9000',\n",
              " 206: '115J53AL030X9676',\n",
              " 207: '117J61A3790X5809',\n",
              " 208: '117V44A3790X5809',\n",
              " 209: '11BP01A2842X6813',\n",
              " 210: '11BS01A2842X5803',\n",
              " 211: '120M34A1116X5640',\n",
              " 212: '120V44A1375X5803',\n",
              " 213: '121B24A3356X0100',\n",
              " 214: '121B54A3234X5302',\n",
              " 215: '121L45A7740X9717',\n",
              " 216: '121L45A7741X9718',\n",
              " 217: '121M15A7867X9631',\n",
              " 218: '121P23A7682X1892',\n",
              " 219: '121P45B3360X5830',\n",
              " 220: '121R07A7741X9718',\n",
              " 221: '121R27A6662X5824',\n",
              " 222: '121V33A6662X5824',\n",
              " 223: '121V45A1212X9000',\n",
              " 224: '122J02X3376X0891',\n",
              " 225: '123T04A4434X5864',\n",
              " 226: '123T04A4435X0200',\n",
              " 227: '124E11DM315X1848',\n",
              " 228: '124E55AM763X0200',\n",
              " 229: '124J08AM762X1650',\n",
              " 230: '124S17AM762X1650',\n",
              " 231: '124S24AM126X1852',\n",
              " 232: '124S43AM411X1884',\n",
              " 233: '124S55AM128X0872',\n",
              " 234: '124T46AM720X0861',\n",
              " 235: '124V03AS211X5685',\n",
              " 236: '125J31WL146X1886',\n",
              " 237: '125V44AL015X9000',\n",
              " 238: '127C10A3665X5687',\n",
              " 239: '127C10A3671X5687',\n",
              " 240: '127J24A2826X5813',\n",
              " 241: '127R40A2970X8854',\n",
              " 242: '140C13A0006X0200',\n",
              " 243: '140M36A0006X0200',\n",
              " 244: '140M39A0006X0200',\n",
              " 245: '140M39A0006X9000',\n",
              " 246: '141B19A3842X4813',\n",
              " 247: '141B58A3356X0100',\n",
              " 248: '141C17X8648X9000',\n",
              " 249: '141G12A1342X5848',\n",
              " 250: '141J51A8986X5645',\n",
              " 251: '141J60A6770X9394',\n",
              " 252: '141J62A8800X5645',\n",
              " 253: '141P08A1186X9330',\n",
              " 254: '141P23A6614X8830',\n",
              " 255: '141P36A6776X4813',\n",
              " 256: '141P62A1342X0823',\n",
              " 257: '141P62A7631X5844',\n",
              " 258: '141P62A7642X1817',\n",
              " 259: '141R05A1300X5824',\n",
              " 260: '141R29A8654X5607',\n",
              " 261: '141R68A6754X5801',\n",
              " 262: '141R70A1194X4292',\n",
              " 263: '141R70A1336X3822',\n",
              " 264: '141V01A7608X8830',\n",
              " 265: '141V35A6776X5813',\n",
              " 266: '142J04A3399X9000',\n",
              " 267: '142J04A3401X5652',\n",
              " 268: '142V11A3406X5803',\n",
              " 269: '143P22AS011X5878',\n",
              " 270: '143R20ST047X0200',\n",
              " 271: '143S04A4044X8854',\n",
              " 272: '143S07A4050X5803',\n",
              " 273: '143S20A4005X0878',\n",
              " 274: '143T04LA043X0200',\n",
              " 275: '143T09A4472X0200',\n",
              " 276: '143T12A4463X0200',\n",
              " 277: '143T12A4464X0200',\n",
              " 278: '143T12B4477X0803',\n",
              " 279: '143T12B4477X0805',\n",
              " 280: '143T52A4040X5810',\n",
              " 281: '144G54AM002X8400',\n",
              " 282: '144G60AM134X0878',\n",
              " 283: '144M02AM303X5810',\n",
              " 284: '144R14BM724X5801',\n",
              " 285: '144S05AM009X6810',\n",
              " 286: '144S21AM074X5620',\n",
              " 287: '144S45AM727X4492',\n",
              " 288: '144S49BD603X4862',\n",
              " 289: '144S49BK603X4862',\n",
              " 290: '144S49FM603X0854',\n",
              " 291: '144S49IB603X0854',\n",
              " 292: '144S49MO603X0854',\n",
              " 293: '144S49PB603X4862',\n",
              " 294: '144S49PF603X0854',\n",
              " 295: '144S60DM134X9678',\n",
              " 296: '144S71AM120X3818',\n",
              " 297: '144S73AM067X4819',\n",
              " 298: '144S73AM067X6819',\n",
              " 299: '144S76AM002X8400',\n",
              " 300: '144S76AM002X9000',\n",
              " 301: '144S88AM115X8530',\n",
              " 302: '144S88AM603X0854',\n",
              " 303: '144S99AM074X8400',\n",
              " 304: '144T46AM118X0854',\n",
              " 305: '144T51AM603X4862',\n",
              " 306: '144T51AM603X6862',\n",
              " 307: '144T51CF603X4862',\n",
              " 308: '144T51LA603X0854',\n",
              " 309: '144T51PC603X4862',\n",
              " 310: '145C55WL017X9801',\n",
              " 311: '146C04AF010X8790',\n",
              " 312: '146C20AF003X5610',\n",
              " 313: '146C65AF003X8790',\n",
              " 314: '146G07AF218X0825',\n",
              " 315: '146M16AF010X8790',\n",
              " 316: '146V19AF010X0201',\n",
              " 317: '146V19AF218X0823',\n",
              " 318: '146V19AF510X8250',\n",
              " 319: '147C23A2771X5830',\n",
              " 320: '147C23A2968X8854',\n",
              " 321: '147C32A2760X9000',\n",
              " 322: '147J14A3336X1702',\n",
              " 323: '147J42A2826X4856',\n",
              " 324: '147J42A2826X6813',\n",
              " 325: '147P21A2826X5813',\n",
              " 326: '147P65B2120X3905',\n",
              " 327: '147V44A2114X9000',\n",
              " 328: '151J46A1145X5740',\n",
              " 329: '151J62A1166X9000',\n",
              " 330: '151L05A1166X9000',\n",
              " 331: '151M50A7608X2817',\n",
              " 332: '151M59A7794X6522',\n",
              " 333: '151P19A5222X1994',\n",
              " 334: '151P35A1145X8625',\n",
              " 335: '151R19A6676X8830',\n",
              " 336: '151R28A1166X0200',\n",
              " 337: '151R30A1166X3250',\n",
              " 338: '151R41A1212X3250',\n",
              " 339: '151R72A6602X6628',\n",
              " 340: '151V35A6842X1831',\n",
              " 341: '152R10A3440X5712',\n",
              " 342: '152V11A3243X0803',\n",
              " 343: '152V41A3432X5516',\n",
              " 344: '152V42A3440X5712',\n",
              " 345: '153T12DA454X0803',\n",
              " 346: '154S11AM007X6606',\n",
              " 347: '154S11AM007X8355',\n",
              " 348: '154S32AM120X0830',\n",
              " 349: '154S55AM114X9330',\n",
              " 350: '156M29AF003X9000',\n",
              " 351: '156M88AF010X1460',\n",
              " 352: '156V19AF010X5645',\n",
              " 353: '157C09A2982X0879',\n",
              " 354: '157J24A2982X0879',\n",
              " 355: '157R40A2732X0835',\n",
              " 356: '157R40A2737X3839',\n",
              " 357: '157V49A3439X8876',\n",
              " 358: '15BS07A2851X5803',\n",
              " 359: '210C43A1810X5803',\n",
              " 360: '210M28A0006X0200',\n",
              " 361: '210M28A1116X3250',\n",
              " 362: '210M40A1375X5803',\n",
              " 363: '211B54A3771X0819',\n",
              " 364: '211J22A1166X0200',\n",
              " 365: '211J22A1166X9000',\n",
              " 366: '211J57A3863X1879',\n",
              " 367: '211L14X6601X0200',\n",
              " 368: '211L19X8808X1900',\n",
              " 369: '211L20X6601X0200',\n",
              " 370: '211L26A7802X0869',\n",
              " 371: '211P32A1166X5645',\n",
              " 372: '211P32A1166X9000',\n",
              " 373: '211P33A1110X9330',\n",
              " 374: '211P33A1166X5645',\n",
              " 375: '211R35A1166X4150',\n",
              " 376: '211R36A7150X5802',\n",
              " 377: '211R66A3863X1879',\n",
              " 378: '211V07A3486X4869',\n",
              " 379: '211V10A6102X0200',\n",
              " 380: '213P03A4077X4855',\n",
              " 381: '213P03A4077X5881',\n",
              " 382: '214E27AM925X1998',\n",
              " 383: '214G38AM901X1998',\n",
              " 384: '214G50AM720X4869',\n",
              " 385: '214G50AM903X1998',\n",
              " 386: '214P17AM045X5865',\n",
              " 387: '214R05AM905X1998',\n",
              " 388: '214S45AM118X0851',\n",
              " 389: '214S87AM715X5645',\n",
              " 390: '214S97AT903X1998',\n",
              " 391: '214V06AM045X5865',\n",
              " 392: '215C62WL033X1998',\n",
              " 393: '215J22AL015X9000',\n",
              " 394: '216C44AF221X5801',\n",
              " 395: '216G18AF003X8450',\n",
              " 396: '216V19AF222X0200',\n",
              " 397: '216V19AF222X5810',\n",
              " 398: '217C21A2987X1998',\n",
              " 399: '217C28A2864X9681',\n",
              " 400: '217P43S2975X1998',\n",
              " 401: '217R40A2977X5803',\n",
              " 402: '218C74AL815X0200',\n",
              " 403: '218C74AL815X1445',\n",
              " 404: '220J95A1116X2660',\n",
              " 405: '221B54A3846X2826',\n",
              " 406: '221B54A3846X4856',\n",
              " 407: '221J36A1162X4494',\n",
              " 408: '221J37A8166X1994',\n",
              " 409: '221J38A8801X9000',\n",
              " 410: '221J65L7607X1029',\n",
              " 411: '221J90A3846X5813',\n",
              " 412: '221J97A3277X4874',\n",
              " 413: '221L12A6715X5598',\n",
              " 414: '221P30A6079X9756',\n",
              " 415: '221R08A1162X9000',\n",
              " 416: '221R26A5110X6240',\n",
              " 417: '221R39A1166X9000',\n",
              " 418: '221R51A1152X5855',\n",
              " 419: '221R58A1212X0200',\n",
              " 420: '221R58A1212X3250',\n",
              " 421: '221R81A3802X0861',\n",
              " 422: '221R90A1166X9000',\n",
              " 423: '221V09A1166X9000',\n",
              " 424: '221V21A5110X2660',\n",
              " 425: '221V33A6829X5897',\n",
              " 426: '221V42S1212X9000',\n",
              " 427: '221V66A1313X3832',\n",
              " 428: '221V68A1004X3832',\n",
              " 429: '221V71A1003X3832',\n",
              " 430: '223G01A4081X4804',\n",
              " 431: '223T18A4499X4804',\n",
              " 432: '223T19A4497X0200',\n",
              " 433: '224S09AM308X4800',\n",
              " 434: '224S13AM403X6873',\n",
              " 435: '224S34AM011X5855',\n",
              " 436: '224S51AM712X5855',\n",
              " 437: '224S55AM010X2875',\n",
              " 438: '224V13BM508X9000',\n",
              " 439: '224V50AM110X5882',\n",
              " 440: '225J87AL118X0200',\n",
              " 441: '225P50AL118X0200',\n",
              " 442: '227B39A3339X1719',\n",
              " 443: '227M39A2827X9000',\n",
              " 444: '227M65A3905X5634',\n",
              " 445: '227M67A2350X6240',\n",
              " 446: '227P53A2826X2826',\n",
              " 447: '22BP08F2825X2825',\n",
              " 448: '241B05A7729X9000',\n",
              " 449: '241B26A6133X0200',\n",
              " 450: '241B32A3356X0100',\n",
              " 451: '241B61A3504X0863',\n",
              " 452: '241J38A1030X9000',\n",
              " 453: '241J61A6102X9000',\n",
              " 454: '241L06A6102X9000',\n",
              " 455: '241M03A1125X9330',\n",
              " 456: '241P01A1166X9000',\n",
              " 457: '241P04S1166X9000',\n",
              " 458: '241R30A1211X9000',\n",
              " 459: '241R36A7608X5830',\n",
              " 460: '241R45A3504X9363',\n",
              " 461: '241R53A7729X9000',\n",
              " 462: '241V19A1162X9000',\n",
              " 463: '241V20X1162X9000',\n",
              " 464: '241V29A6746X9637',\n",
              " 465: '241V33A6633X9729',\n",
              " 466: '241V52A1162X9000',\n",
              " 467: '242E14S3525X0100',\n",
              " 468: '242P04S3374X9000',\n",
              " 469: '242P04S3525X0100',\n",
              " 470: '242V11A3526X5881',\n",
              " 471: '243T20A4082X9330',\n",
              " 472: '244P40AM512X9000',\n",
              " 473: '244S15AM730X4808',\n",
              " 474: '244S15IB730X4808',\n",
              " 475: '244S15LA730X5808',\n",
              " 476: '244S15ST730X4808',\n",
              " 477: '244S15TA730X4808',\n",
              " 478: '244S25BM401X2830',\n",
              " 479: '244S28AM734X6890',\n",
              " 480: '244S57ST054X4453',\n",
              " 481: '244S73SN320X0849',\n",
              " 482: '244S94AM054X9000',\n",
              " 483: '244S97AM730X2808',\n",
              " 484: '244S97BA730X2808',\n",
              " 485: '244S98AM054X4453',\n",
              " 486: '244S98BA054X5318',\n",
              " 487: '244T50AM140X0930',\n",
              " 488: '246G31AF010X8530',\n",
              " 489: '246M79AF010X8785',\n",
              " 490: '246V21AF003X1753',\n",
              " 491: '247B36A3339X9000',\n",
              " 492: '247B37A3126X0815',\n",
              " 493: '247C04A3332X1700',\n",
              " 494: '247C22A2756X0998',\n",
              " 495: '247C26A2757X0998',\n",
              " 496: '247C30A3943X2830',\n",
              " 497: '247P08A3332X1700',\n",
              " 498: '247P69A3439X8876',\n",
              " 499: '248C47AL831X2817',\n",
              " 500: '248C81AL800X7680',\n",
              " 501: '248C89AL813X0200',\n",
              " 502: '251J47A2641X9820',\n",
              " 503: '251J50K7879X9255',\n",
              " 504: '251J51S1186X9330',\n",
              " 505: '251J55A1186X9330',\n",
              " 506: '251L22B6602X9000',\n",
              " 507: '251L24A6602X2910',\n",
              " 508: '251P04A3221X9000',\n",
              " 509: '251P77A6849X0810',\n",
              " 510: '251R25X6601X9000',\n",
              " 511: '251R44A1166X9000',\n",
              " 512: '251R81B3802X1821',\n",
              " 513: '251V15A1030X8700',\n",
              " 514: '251V15A1186X9330',\n",
              " 515: '251V15X1166X9000',\n",
              " 516: '251V16A3221X9000',\n",
              " 517: '251V19A1186X9330',\n",
              " 518: '254G60EM134X9661',\n",
              " 519: '254P55AM880X0878',\n",
              " 520: '254R17AM523X9000',\n",
              " 521: '254S03AM131X8810',\n",
              " 522: '254S54AM048X1700',\n",
              " 523: '254S75AM845X9000',\n",
              " 524: '254S78AM149X4854',\n",
              " 525: '254V53AM514X9330',\n",
              " 526: '257J64A3754X1800',\n",
              " 527: '257J98A3125X0810',\n",
              " 528: '257M76A3754X1800',\n",
              " 529: '257V34A1258X9330',\n",
              " 530: '257V36A1298X9372',\n",
              " 531: '258G19AL801X9580',\n",
              " 532: '258V39AL801X9580',\n",
              " 533: '25BB11A2892X3550',\n",
              " 534: '25BS11A2891X5550',\n",
              " 535: '310M67A1375X9000',\n",
              " 536: '311J01A3105X1652',\n",
              " 537: '311J09B1166X4220',\n",
              " 538: '311J11A8810X9000',\n",
              " 539: '311P30A6852X1998',\n",
              " 540: '311R88A7631X9330',\n",
              " 541: '311V29A6856X0825',\n",
              " 542: '312P06A3567X4228',\n",
              " 543: '312P23A3570X4810',\n",
              " 544: '312R17A3570X4810',\n",
              " 545: '312V11A3546X1998',\n",
              " 546: '312V11A3567X4228',\n",
              " 547: '312V20A3554X5549',\n",
              " 548: '314S85AM713X5800',\n",
              " 549: '317C27A3905X9000',\n",
              " 550: '317J31A2827X9000',\n",
              " 551: '321B36A3356X9000',\n",
              " 552: '321J19A3141X9330',\n",
              " 553: '321J44A3332X9000',\n",
              " 554: '321P05A3141X0930',\n",
              " 555: '321P05A3607X9000',\n",
              " 556: '321P05B3157X1802',\n",
              " 557: '321V31A3249X1297',\n",
              " 558: '323T09A4428X0200',\n",
              " 559: '323T43A4416X0200',\n",
              " 560: '327B20A3141X9330',\n",
              " 561: '327P05A3144X6667',\n",
              " 562: '327R14A3332X1700',\n",
              " 563: '841V01A1166X3386',\n",
              " 564: '841V01A1166X4150',\n",
              " 565: '843T03TA428X0200',\n",
              " 566: '844S81AM115X9000',\n",
              " 567: '854E01AM507X0854',\n",
              " 568: '911B54A3802X0849',\n",
              " 569: '911B54A3810X0854',\n",
              " 570: '911J29A3802X0812',\n",
              " 571: '913T03JA428X0800',\n",
              " 572: '913T06JB425X6803',\n",
              " 573: '917P85A6634X5640',\n",
              " 574: '921J12A6801X4823',\n",
              " 575: '921J26A8928X9000',\n",
              " 576: '922P02A3932X5846',\n",
              " 577: '92BP01A2816X5863',\n",
              " 578: '940C08A1068X8741',\n",
              " 579: '941G03A1162X5645',\n",
              " 580: '941J06A8709X3250',\n",
              " 581: '941J06A8709X4220',\n",
              " 582: '941R60A8928X0200',\n",
              " 583: '943T03A4431X0856',\n",
              " 584: '943T05CP430X0854',\n",
              " 585: '944E01AM510X0849',\n",
              " 586: '944E20FM507X0854',\n",
              " 587: '944E20IB507X0849',\n",
              " 588: '944E20MY507X0852',\n",
              " 589: '944E20MY507X0856',\n",
              " 590: '944E20PF507X0849',\n",
              " 591: '944E20ST507X0856',\n",
              " 592: '944E50AM510X0854',\n",
              " 593: '944G04AM406X0825',\n",
              " 594: '944S26RB012X1815',\n",
              " 595: '944S95ST603X0854',\n",
              " 596: '944S96CP032X0852',\n",
              " 597: '944S96CP032X0854',\n",
              " 598: '944S96FM032X0852',\n",
              " 599: '944S96FM032X0854',\n",
              " 600: '944S96IB032X0856',\n",
              " 601: '944S96MY032X0849',\n",
              " 602: '944S96MY032X0854',\n",
              " 603: '944S96ST032X0852',\n",
              " 604: '94BB01A2801X0852',\n",
              " 605: '950V36A1190X6808',\n",
              " 606: '951B03A6028X9309',\n",
              " 607: '951B08A3952X6817',\n",
              " 608: '951B13A2016X9330',\n",
              " 609: '951J26A1186X9330',\n",
              " 610: '951J33A3958X0800',\n",
              " 611: '951J45A1182X6808',\n",
              " 612: '951L38A7810X9000',\n",
              " 613: '951P19A1184X6808',\n",
              " 614: '951R12A1184X9330',\n",
              " 615: '951R22A1166X5645',\n",
              " 616: '951V46A1202X5825',\n",
              " 617: '952E01A3321X5425',\n",
              " 618: '952J07A3227X5430',\n",
              " 619: '952P07A3321X5425',\n",
              " 620: '953T03SD440X0200',\n",
              " 621: '953T03SG428X0300',\n",
              " 622: '953T03SG440X0200',\n",
              " 623: '953T03SP428X1000',\n",
              " 624: '954E25AM201X9000',\n",
              " 625: '954E51AM509X6808',\n",
              " 626: '954T31AM001X9000',\n",
              " 627: 'S00074NEEM900',\n",
              " 628: 'S0007ONMJM44M',\n",
              " 629: 'S0007ONMJM81P',\n",
              " 630: 'S0007OVRBM69H',\n",
              " 631: 'S0007OVRBM900',\n",
              " 632: 'S0011ONMJM54H',\n",
              " 633: 'S0011ONMJM77P',\n",
              " 634: 'S0011OVRBM323',\n",
              " 635: 'S0011PVRBM323',\n",
              " 636: 'S0020ONMJM54H',\n",
              " 637: 'S0020OVRBM90B',\n",
              " 638: 'S0020PVRBM414',\n",
              " 639: 'S0074ILOIM90B',\n",
              " 640: 'S0074OKSFM50E',\n",
              " 641: 'S0074ONMJM45U',\n",
              " 642: 'S0074OSBXM911',\n",
              " 643: 'S0074OTYGM886',\n",
              " 644: 'S0074OVRBM323',\n",
              " 645: 'S0074OVRBM49P',\n",
              " 646: 'S0074OVRBM669',\n",
              " 647: 'S0074OVRBM81B',\n",
              " 648: 'S0074OVRBM90B',\n",
              " 649: 'S0074OWECM10L',\n",
              " 650: 'S0074PCALM900',\n",
              " 651: 'S0074PVRBM414',\n",
              " 652: 'S0105CNPIM29O',\n",
              " 653: 'S0105OSNIM37E',\n",
              " 654: 'S0110ONMJM43F',\n",
              " 655: 'S0126JAETM64K',\n",
              " 656: 'S0126JWECM64K',\n",
              " 657: 'S0126OSDLM911',\n",
              " 658: 'S0126OSNIM37E',\n",
              " 659: 'S0126OVRBM49P',\n",
              " 660: 'S0126OVRBM68P',\n",
              " 661: 'S0126OVRBM69P',\n",
              " 662: 'S0126OVRBM900',\n",
              " 663: 'S0126PSKCM090',\n",
              " 664: 'S0126PVRBM323',\n",
              " 665: 'S0178OADUM11G',\n",
              " 666: 'S0178ONMJM52R',\n",
              " 667: 'S0178ONXSM01E',\n",
              " 668: 'S0178OVRBM12F',\n",
              " 669: 'S0178OVRBM14F',\n",
              " 670: 'S0178OVRBM71P',\n",
              " 671: 'S0178OVRBM900',\n",
              " 672: 'S0178OVRBM94B',\n",
              " 673: 'S0178SSRGM49E',\n",
              " 674: 'S0179CGSCM941',\n",
              " 675: 'S0181ONMJM398',\n",
              " 676: 'S0181ONMJM76P',\n",
              " 677: 'S0181ONMJM77P',\n",
              " 678: 'S0181OVRBM27Y',\n",
              " 679: 'S0181OVRBM81B',\n",
              " 680: 'S0181PNMJM08Z',\n",
              " 681: 'S0200ONMJM900',\n",
              " 682: 'S0204JAHGXM432',\n",
              " 683: 'S0204JAHKXM16Y',\n",
              " 684: 'S0204JANHXM07J',\n",
              " 685: 'S0204JLERXM41G',\n",
              " 686: 'S0204OAHGXM40M',\n",
              " 687: 'S0204OAHGXM716',\n",
              " 688: 'S0204OAHGXM830',\n",
              " 689: 'S0204OAHKXM16Y',\n",
              " 690: 'S0204OAHKXM50P',\n",
              " 691: 'S0204OAHKXM61P',\n",
              " 692: 'S0204OBBBM941',\n",
              " 693: 'S0204OCYMXM010',\n",
              " 694: 'S0204OLERXM42R',\n",
              " 695: 'S0204ONMJM42R',\n",
              " 696: 'S0204ONMJM900',\n",
              " 697: 'S0204OOCCM71P',\n",
              " 698: 'S0204ORERM885',\n",
              " 699: 'S0204OSAKM49E',\n",
              " 700: 'S0204OSJAM941',\n",
              " 701: 'S0204OVRBM41R',\n",
              " 702: 'S0204OVRBM50R',\n",
              " 703: 'S0204OVRBM97B',\n",
              " 704: 'S0204PAHGXM50R',\n",
              " 705: 'S0204PAHKXM030',\n",
              " 706: 'S0204PAHKXM61P',\n",
              " 707: 'S0204PLERXM41G',\n",
              " 708: 'S0206ONMJM50R',\n",
              " 709: 'S0206ONMJM900',\n",
              " 710: 'S0311CNOEM40R',\n",
              " 711: 'S0311OVKQM04J',\n",
              " 712: 'S0311SWLIM989',\n",
              " 713: 'S0328CNOSM87B',\n",
              " 714: 'S0328CNOSM900',\n",
              " 715: 'S0328OKSKM39E',\n",
              " 716: 'S0328OSKNM87K',\n",
              " 717: 'S0328OUIGM54P',\n",
              " 718: 'S0328OWDAM90B',\n",
              " 719: 'S0478ONMJM60P',\n",
              " 720: 'S0478ONMJM81B',\n",
              " 721: 'S0478ONMJM94B',\n",
              " 722: 'S0607CLCJM35R',\n",
              " 723: 'S0617OSKNM97K',\n",
              " 724: 'S0617OVKKM398',\n",
              " 725: 'S0617OVKKM85B',\n",
              " 726: 'S0617RSKNM76K',\n",
              " 727: 'S0619OVKKM398',\n",
              " 728: 'S0619OWDAM413',\n",
              " 729: 'S0632CLCJM35R',\n",
              " 730: 'S0632CSKSM090',\n",
              " 731: 'S0634CLCJM42R',\n",
              " 732: 'S0634CNOSM04B',\n",
              " 733: 'S0634CNOSM29O',\n",
              " 734: 'S0650OWDAM42R',\n",
              " 735: 'S0742ONMJM94B',\n",
              " 736: 'S0744OVRBM49P',\n",
              " 737: 'S0841OVRBM74P',\n",
              " 738: 'S0853ONMJM97B',\n",
              " 739: 'S0856BNERM930',\n",
              " 740: 'S0856BNERM941',\n",
              " 741: 'S0856OAATM37O',\n",
              " 742: 'S0856OLDQM31E',\n",
              " 743: 'S0856OROZM929',\n",
              " 744: 'S0856ORWOM70H',\n",
              " 745: 'S0856OWCBM030',\n",
              " 746: 'S0856OWCBM74P',\n",
              " 747: 'S0856OWCBM900',\n",
              " 748: 'S0872ONGHM900',\n",
              " 749: 'S0872ONHBM030',\n",
              " 750: 'S0872ONMJM77P',\n",
              " 751: 'S0872ONMJM900',\n",
              " 752: 'S0872OVRBM26Y',\n",
              " 753: 'S0878ONMJM01Z',\n",
              " 754: 'S0918OAYCM17A',\n",
              " 755: 'S0918ONMJM67P',\n",
              " 756: 'S0918ONMJM97B',\n",
              " 757: 'S0935ONMJM76P',\n",
              " 758: 'S0935OWCBM03Z',\n",
              " 759: 'S0946OVRBM900',\n",
              " 760: 'S0949HAQRJM042',\n",
              " 761: 'S0959ONMJM29Y',\n",
              " 762: 'S0965ONMJM69H',\n",
              " 763: 'S0965ONMJM76P',\n",
              " 764: 'S0977BNMJM030',\n",
              " 765: 'S0977BNMJM900',\n",
              " 766: 'S0981ONMJM030',\n",
              " 767: 'S1094CBTEM928',\n",
              " 768: 'S1095ZVXXM888',\n",
              " 769: 'S2012CNMJM41R',\n",
              " 770: 'S2022UEMUM31E',\n",
              " 771: 'S2022UROQM808',\n",
              " 772: 'S2022UWHCM01H',\n",
              " 773: 'S2022UWHCM900',\n",
              " 774: 'S2022WNGIM900',\n",
              " 775: 'S204SJAHGXM04B',\n",
              " 776: 'S204SJAHGXM10V',\n",
              " 777: 'S204SJAHGXM225',\n",
              " 778: 'S204SJAHGXM54H',\n",
              " 779: 'S204SJAHKXM55H',\n",
              " 780: 'S204SJAHKXM821',\n",
              " 781: 'S204SOAHGXM334',\n",
              " 782: 'S204SOAHGXM659',\n",
              " 783: 'S204SOCYMXM428',\n",
              " 784: 'S204SOCYMXM62P',\n",
              " 785: 'S204SOCYMXM649',\n",
              " 786: 'S204SOLMJXM13L',\n",
              " 787: 'S204SPAHGXM716',\n",
              " 788: 'S204SPAHKXM61P',\n",
              " 789: 'S204SPLERXM35M',\n",
              " 790: 'S204SPLERXM42R',\n",
              " 791: 'S2057OBAEM116',\n",
              " 792: 'S2057OBAEM41G',\n",
              " 793: 'S2057OWPJM900',\n",
              " 794: 'S2057PBAEM90B',\n",
              " 795: 'S2058JFIAM884',\n",
              " 796: 'S2084OBAEM68P',\n",
              " 797: 'S2084OSKCM07J',\n",
              " 798: 'S2084OWBHM59P',\n",
              " 799: 'S2086OBAEM60P',\n",
              " 800: 'S2086OBAEM81B',\n",
              " 801: 'S2086OSKCM07J',\n",
              " 802: 'S2088UMMWM900',\n",
              " 803: 'S2088USKCM26L',\n",
              " 804: 'S2089USKCM07J',\n",
              " 805: 'S2110UMOSM49P',\n",
              " 806: 'S2110UMOSM900',\n",
              " 807: 'S2110UMOSM991',\n",
              " 808: 'S2113PBAEM90B',\n",
              " 809: 'S2114UTZQM917',\n",
              " 810: 'S2123UTZQM928',\n",
              " 811: 'S2136UWGNM920',\n",
              " 812: 'S2152OBAEM41G',\n",
              " 813: 'S3003CLLMM900',\n",
              " 814: 'S3003CNPIM900',\n",
              " 815: 'S3003CVYIM92K',\n",
              " 816: 'S5030UWHCM04Z',\n",
              " 817: 'S5030UWHCM56R',\n",
              " 818: 'S5032UWHCM81B',\n",
              " 819: 'S5032UWHCM900',\n",
              " 820: 'S5033UWHCM65H',\n",
              " 821: 'S5034UWHCM68H',\n",
              " 822: 'S5037UNGIM900',\n",
              " 823: 'S5037UWHCM44M',\n",
              " 824: 'S5039UWHCM116',\n",
              " 825: 'S5043UNSQM45M',\n",
              " 826: 'S50864HPVM15F',\n",
              " 827: 'S5086UNGXM41G',\n",
              " 828: 'S5086UWFQM93B',\n",
              " 829: 'S5086UWHCM45M',\n",
              " 830: 'S5087WNSQM65H',\n",
              " 831: 'S5091UWHCM030',\n",
              " 832: 'S5091UWHCM56R',\n",
              " 833: 'S5091UWHCM74P',\n",
              " 834: 'S5097WNGIM900',\n",
              " 835: 'S5098UWHCM01H',\n",
              " 836: 'S5105UWHCM26Y',\n",
              " 837: 'S5106UWHCM50P',\n",
              " 838: 'S5108UWHCM03Z',\n",
              " 839: 'S5109UMOLM03Z',\n",
              " 840: 'S5130UWHCM32Y',\n",
              " 841: 'S5132UWHCM45U',\n",
              " 842: 'S5132UWHCM81B',\n",
              " 843: 'S5134USJSM941',\n",
              " 844: 'S5134UWHCM030',\n",
              " 845: 'S5135UNGXM08Z',\n",
              " 846: 'S5137URXUM930',\n",
              " 847: 'S5137USJSM941',\n",
              " 848: 'S5140UNGXM09Z',\n",
              " 849: 'S5414CTZQM928',\n",
              " 850: 'S5418VRIWM928',\n",
              " 851: 'S5418VRIWM932',\n",
              " 852: 'S5420VRIWM928',\n",
              " 853: 'S5440INSYM928',\n",
              " 854: 'S5440OBQDM993',\n",
              " 855: 'S5440SRMOM042',\n",
              " 856: 'S5440SRMOM928',\n",
              " 857: 'S5475ZBBIM808',\n",
              " 858: 'S5475ZRGFM928',\n",
              " 859: 'S5475ZRHMM918',\n",
              " 860: 'S5475ZRIWM974',\n",
              " 861: 'S5475ZTDTM808',\n",
              " 862: 'S5476CTZQM928',\n",
              " 863: 'S5480VREYM49E',\n",
              " 864: 'S5480VTDTM808',\n",
              " 865: 'S5488UNGVM35R',\n",
              " 866: 'S5488UNTRM14F',\n",
              " 867: 'S5493STKUM928',\n",
              " 868: 'S5494SLNCN0N1',\n",
              " 869: 'S5494UTEUM928',\n",
              " 870: 'S5494VNTJM912',\n",
              " 871: 'S5496VRSEM928',\n",
              " 872: 'S5544CGSBM900',\n",
              " 873: 'S5545CGSBM90B',\n",
              " 874: 'S5554BMIGM030',\n",
              " 875: 'S5555CRHMM918',\n",
              " 876: 'S5555CRTYM930',\n",
              " 877: 'S5610CWVGM50H',\n",
              " 878: 'S5610CWVGM50R',\n",
              " 879: 'S5611CCEHM43U',\n",
              " 880: 'S5611CTZQM928',\n",
              " 881: 'S5611CTZQM974',\n",
              " 882: 'S5614CCEHM14F',\n",
              " 883: 'S5614CCEHM423',\n",
              " 884: 'S5614CWGSM919',\n",
              " 885: 'S5614CWVGM35U',\n",
              " 886: 'S5614CWVGM59P',\n",
              " 887: 'S5614SLLOM989',\n",
              " 888: 'S5619CTZQM51E',\n",
              " 889: 'S5619SLLOM989',\n",
              " 890: 'S5628CNPYM50P',\n",
              " 891: 'S5632CBAAM50P',\n",
              " 892: 'S5632CWVGM85B',\n",
              " 893: 'S5642CTZQM974',\n",
              " 894: 'S5647CWVFM928',\n",
              " 895: 'S5652CBAAM41G',\n",
              " 896: 'S5652CBAAM50P',\n",
              " 897: 'S5652CCEHM03Z',\n",
              " 898: 'S5652CCEHM81B',\n",
              " 899: 'S5652CCEHM900',\n",
              " 900: 'S5652CWGSM919',\n",
              " 901: 'S5653CCEHM27Y',\n",
              " 902: 'S5654CCEHM68P',\n",
              " 903: 'S5654CCEHM81B',\n",
              " 904: 'S5659CCEHM90B',\n",
              " 905: 'S5668CTZQM928',\n",
              " 906: 'S5671CCEHM14F',\n",
              " 907: 'S5673CBAAM900',\n",
              " 908: 'S5673CTZQM928',\n",
              " 909: 'S5675CTZQM928',\n",
              " 910: 'S5680CBAAM26Y',\n",
              " 911: 'S5681CCEHM81B',\n",
              " 912: 'S56854NEQM08Z',\n",
              " 913: 'S5685CCEHM14Z',\n",
              " 914: 'S5700CTZQM042',\n",
              " 915: 'S5700CTZQM928',\n",
              " 916: 'S5700CTZQM974',\n",
              " 917: 'S6200BSGQM808',\n",
              " 918: 'S6200OSGQM933',\n",
              " 919: 'S7004CVXSM85B',\n",
              " 920: 'S7005CLLMM900',\n",
              " 921: 'S7014CVYIM20G',\n",
              " 922: 'S7016CVQRM030',\n",
              " 923: 'S7200ONOAM933',\n",
              " 924: 'S7407CSBWM927',\n",
              " 925: 'S7408CSBWM911',\n",
              " 926: 'S7414CSBWM962',\n",
              " 927: 'S8009CVQRM85B',\n",
              " 928: 'S8045VSTJM956',\n",
              " 929: 'AUT44550M531',\n",
              " 930: 'CAL44550M030',\n",
              " 931: 'CAL44550M42R',\n",
              " 932: 'CAL44550M57H',\n",
              " 933: 'CAL44551M83B',\n",
              " 934: 'CAL44551N0',\n",
              " 935: 'CRO44500SM334',\n",
              " 936: 'LEZ44550M42R',\n",
              " 937: 'M0421CNOEM40P',\n",
              " 938: 'M0421CVKKM47R',\n",
              " 939: 'M0421CVKQM92K',\n",
              " 940: 'M0421OANGM06K',\n",
              " 941: 'M0421ORDYM939',\n",
              " 942: 'M0421OWENM19J',\n",
              " 943: 'M0422CNOEM47R',\n",
              " 944: 'M0422ORJMM939',\n",
              " 945: 'M0422ORSTM911',\n",
              " 946: 'M0422OVKKM398',\n",
              " 947: 'M0422PNAGM900',\n",
              " 948: 'M0422PVKKM413',\n",
              " 949: 'M0422SWLIM989',\n",
              " 950: 'M0446CAATXM253',\n",
              " 951: 'M0446CAHLXM225',\n",
              " 952: 'M0446CAHLXM432',\n",
              " 953: 'M0446CAHLXM61P',\n",
              " 954: 'M0446CAPWM05E',\n",
              " 955: 'M0446CAPWM936',\n",
              " 956: 'M0446CAPWM950',\n",
              " 957: 'M0446CBAAM030',\n",
              " 958: 'M0446CBAAM44M',\n",
              " 959: 'M0446CBAAM64H',\n",
              " 960: 'M0446CBAAM900',\n",
              " 961: 'M0446CCEHM900',\n",
              " 962: 'M0446CCYRXM62P',\n",
              " 963: 'M0446CIAAM53E',\n",
              " 964: 'M0446CMMKM925',\n",
              " 965: 'M0446CRBWM38M',\n",
              " 966: 'M0446CRDSM887',\n",
              " 967: 'M0446CRNUM911',\n",
              " 968: 'M0446CSAZM49E',\n",
              " 969: 'M0446CSAZM928',\n",
              " 970: 'M0446CSJGM45E',\n",
              " 971: 'M0446CSNHM37E',\n",
              " 972: 'M0446CTGUM924',\n",
              " 973: 'M0446CTZQM989',\n",
              " 974: 'M0446CWAHM989',\n",
              " 975: 'M0446CWPLM900',\n",
              " 976: 'M0446CWVGM49P',\n",
              " 977: 'M0446CWVGM900',\n",
              " 978: 'M0446IFVKM51R',\n",
              " 979: 'M0446IINFM30U',\n",
              " 980: 'M0446ILLOM50P',\n",
              " 981: 'M0446VAATXM90B',\n",
              " 982: 'M0446VAHLXM16Y',\n",
              " 983: 'M0446VAHLXM79B',\n",
              " 984: 'M0446VAHLXM821',\n",
              " 985: 'M0446VANGXM07J',\n",
              " 986: 'M0446VCYRXM25Y',\n",
              " 987: 'M0447CAATXM334',\n",
              " 988: 'M0447CAATXM645',\n",
              " 989: 'M0447CAATXM66F',\n",
              " 990: 'M0447CAHLXM225',\n",
              " 991: 'M0447CAHLXM40M',\n",
              " 992: 'M0447CAHLXM50R',\n",
              " 993: 'M0447CANGM22L',\n",
              " 994: 'M0447CANWM43R',\n",
              " 995: 'M0447CAPWM45E',\n",
              " 996: 'M0447CBAAM81B',\n",
              " 997: 'M0447CCEHM44U',\n",
              " 998: 'M0447CLEGXM334',\n",
              " 999: 'M0447CRDJM887',\n",
              " ...}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int_to_mmc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "BxhfMmVdHoZM"
      },
      "outputs": [],
      "source": [
        "#@title Preprocessing functions from data_util.py in SimCLR repository (hidden).\n",
        "\n",
        "FLAGS_color_jitter_strength = 0.3\n",
        "CROP_PROPORTION = 0.875  # Standard for ImageNet.\n",
        "\n",
        "\n",
        "def random_apply(func, p, x):\n",
        "  \"\"\"Randomly apply function func to x with probability p.\"\"\"\n",
        "  return tf.cond(\n",
        "      tf.less(tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "              tf.cast(p, tf.float32)),\n",
        "      lambda: func(x),\n",
        "      lambda: x)\n",
        "\n",
        "\n",
        "def random_brightness(image, max_delta, impl='simclrv2'):\n",
        "  \"\"\"A multiplicative vs additive change of brightness.\"\"\"\n",
        "  if impl == 'simclrv2':\n",
        "    factor = tf.random_uniform(\n",
        "        [], tf.maximum(1.0 - max_delta, 0), 1.0 + max_delta)\n",
        "    image = image * factor\n",
        "  elif impl == 'simclrv1':\n",
        "    image = random_brightness(image, max_delta=max_delta)\n",
        "  else:\n",
        "    raise ValueError('Unknown impl {} for random brightness.'.format(impl))\n",
        "  return image\n",
        "\n",
        "\n",
        "def to_grayscale(image, keep_channels=True):\n",
        "  image = tf.image.rgb_to_grayscale(image)\n",
        "  if keep_channels:\n",
        "    image = tf.tile(image, [1, 1, 3])\n",
        "  return image\n",
        "\n",
        "\n",
        "def color_jitter(image,\n",
        "                 strength,\n",
        "                 random_order=True):\n",
        "  \"\"\"Distorts the color of the image.\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    strength: the floating number for the strength of the color augmentation.\n",
        "    random_order: A bool, specifying whether to randomize the jittering order.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  brightness = 0.8 * strength\n",
        "  contrast = 0.8 * strength\n",
        "  saturation = 0.8 * strength\n",
        "  hue = 0.2 * strength\n",
        "  if random_order:\n",
        "    return color_jitter_rand(image, brightness, contrast, saturation, hue)\n",
        "  else:\n",
        "    return color_jitter_nonrand(image, brightness, contrast, saturation, hue)\n",
        "\n",
        "\n",
        "def color_jitter_nonrand(image, brightness=0, contrast=0, saturation=0, hue=0):\n",
        "  \"\"\"Distorts the color of the image (jittering order is fixed).\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    brightness: A float, specifying the brightness for color jitter.\n",
        "    contrast: A float, specifying the contrast for color jitter.\n",
        "    saturation: A float, specifying the saturation for color jitter.\n",
        "    hue: A float, specifying the hue for color jitter.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('distort_color'):\n",
        "    def apply_transform(i, x, brightness, contrast, saturation, hue):\n",
        "      \"\"\"Apply the i-th transformation.\"\"\"\n",
        "      if brightness != 0 and i == 0:\n",
        "        x = random_brightness(x, max_delta=brightness)\n",
        "      elif contrast != 0 and i == 1:\n",
        "        x = tf.image.random_contrast(\n",
        "            x, lower=1-contrast, upper=1+contrast)\n",
        "      elif saturation != 0 and i == 2:\n",
        "        x = tf.image.random_saturation(\n",
        "            x, lower=1-saturation, upper=1+saturation)\n",
        "      elif hue != 0:\n",
        "        x = tf.image.random_hue(x, max_delta=hue)\n",
        "      return x\n",
        "\n",
        "    for i in range(4):\n",
        "      image = apply_transform(i, image, brightness, contrast, saturation, hue)\n",
        "      image = tf.clip_by_value(image, 0., 1.)\n",
        "    return image\n",
        "\n",
        "\n",
        "def color_jitter_rand(image, brightness=0, contrast=0, saturation=0, hue=0):\n",
        "  \"\"\"Distorts the color of the image (jittering order is random).\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    brightness: A float, specifying the brightness for color jitter.\n",
        "    contrast: A float, specifying the contrast for color jitter.\n",
        "    saturation: A float, specifying the saturation for color jitter.\n",
        "    hue: A float, specifying the hue for color jitter.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('distort_color'):\n",
        "    def apply_transform(i, x):\n",
        "      \"\"\"Apply the i-th transformation.\"\"\"\n",
        "      def brightness_foo():\n",
        "        if brightness == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return random_brightness(x, max_delta=brightness)\n",
        "      def contrast_foo():\n",
        "        if contrast == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_contrast(x, lower=1-contrast, upper=1+contrast)\n",
        "      def saturation_foo():\n",
        "        if saturation == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_saturation(\n",
        "              x, lower=1-saturation, upper=1+saturation)\n",
        "      def hue_foo():\n",
        "        if hue == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_hue(x, max_delta=hue)\n",
        "      x = tf.cond(tf.less(i, 2),\n",
        "                  lambda: tf.cond(tf.less(i, 1), brightness_foo, contrast_foo),\n",
        "                  lambda: tf.cond(tf.less(i, 3), saturation_foo, hue_foo))\n",
        "      return x\n",
        "\n",
        "    perm = tf.random_shuffle(tf.range(4))\n",
        "    for i in range(4):\n",
        "      image = apply_transform(perm[i], image)\n",
        "      image = tf.clip_by_value(image, 0., 1.)\n",
        "    return image\n",
        "\n",
        "\n",
        "def _compute_crop_shape(\n",
        "    image_height, image_width, aspect_ratio, crop_proportion):\n",
        "  \"\"\"Compute aspect ratio-preserving shape for central crop.\n",
        "  The resulting shape retains `crop_proportion` along one side and a proportion\n",
        "  less than or equal to `crop_proportion` along the other side.\n",
        "  Args:\n",
        "    image_height: Height of image to be cropped.\n",
        "    image_width: Width of image to be cropped.\n",
        "    aspect_ratio: Desired aspect ratio (width / height) of output.\n",
        "    crop_proportion: Proportion of image to retain along the less-cropped side.\n",
        "  Returns:\n",
        "    crop_height: Height of image after cropping.\n",
        "    crop_width: Width of image after cropping.\n",
        "  \"\"\"\n",
        "  image_width_float = tf.cast(image_width, tf.float32)\n",
        "  image_height_float = tf.cast(image_height, tf.float32)\n",
        "\n",
        "  def _requested_aspect_ratio_wider_than_image():\n",
        "    crop_height = tf.cast(tf.rint(\n",
        "        crop_proportion / aspect_ratio * image_width_float), tf.int32)\n",
        "    crop_width = tf.cast(tf.rint(\n",
        "        crop_proportion * image_width_float), tf.int32)\n",
        "    return crop_height, crop_width\n",
        "\n",
        "  def _image_wider_than_requested_aspect_ratio():\n",
        "    crop_height = tf.cast(\n",
        "        tf.rint(crop_proportion * image_height_float), tf.int32)\n",
        "    crop_width = tf.cast(tf.rint(\n",
        "        crop_proportion * aspect_ratio *\n",
        "        image_height_float), tf.int32)\n",
        "    return crop_height, crop_width\n",
        "\n",
        "  return tf.cond(\n",
        "      aspect_ratio > image_width_float / image_height_float,\n",
        "      _requested_aspect_ratio_wider_than_image,\n",
        "      _image_wider_than_requested_aspect_ratio)\n",
        "\n",
        "\n",
        "def center_crop(image, height, width, crop_proportion):\n",
        "  \"\"\"Crops to center of image and rescales to desired size.\n",
        "  Args:\n",
        "    image: Image Tensor to crop.\n",
        "    height: Height of image to be cropped.\n",
        "    width: Width of image to be cropped.\n",
        "    crop_proportion: Proportion of image to retain along the less-cropped side.\n",
        "  Returns:\n",
        "    A `height` x `width` x channels Tensor holding a central crop of `image`.\n",
        "  \"\"\"\n",
        "  shape = tf.shape(image)\n",
        "  image_height = shape[0]\n",
        "  image_width = shape[1]\n",
        "  crop_height, crop_width = _compute_crop_shape(\n",
        "      image_height, image_width, height / width, crop_proportion)\n",
        "  offset_height = ((image_height - crop_height) + 1) // 2\n",
        "  offset_width = ((image_width - crop_width) + 1) // 2\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_height, offset_width, crop_height, crop_width)\n",
        "\n",
        "  image = tf.image.resize_bicubic([image], [height, width])[0]\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def distorted_bounding_box_crop(image,\n",
        "                                bbox,\n",
        "                                min_object_covered=0.1,\n",
        "                                aspect_ratio_range=(0.75, 1.33),\n",
        "                                area_range=(0.05, 1.0),\n",
        "                                max_attempts=100,\n",
        "                                scope=None):\n",
        "  \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\n",
        "  See `tf.image.sample_distorted_bounding_box` for more documentation.\n",
        "  Args:\n",
        "    image: `Tensor` of image data.\n",
        "    bbox: `Tensor` of bounding boxes arranged `[1, num_boxes, coords]`\n",
        "        where each coordinate is [0, 1) and the coordinates are arranged\n",
        "        as `[ymin, xmin, ymax, xmax]`. If num_boxes is 0 then use the whole\n",
        "        image.\n",
        "    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n",
        "        area of the image must contain at least this fraction of any bounding\n",
        "        box supplied.\n",
        "    aspect_ratio_range: An optional list of `float`s. The cropped area of the\n",
        "        image must have an aspect ratio = width / height within this range.\n",
        "    area_range: An optional list of `float`s. The cropped area of the image\n",
        "        must contain a fraction of the supplied image within in this range.\n",
        "    max_attempts: An optional `int`. Number of attempts at generating a cropped\n",
        "        region of the image of the specified constraints. After `max_attempts`\n",
        "        failures, return the entire image.\n",
        "    scope: Optional `str` for name scope.\n",
        "  Returns:\n",
        "    (cropped image `Tensor`, distorted bbox `Tensor`).\n",
        "  \"\"\"\n",
        "  with tf.name_scope(scope, 'distorted_bounding_box_crop', [image, bbox]):\n",
        "    shape = tf.shape(image)\n",
        "    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n",
        "        shape,\n",
        "        bounding_boxes=bbox,\n",
        "        min_object_covered=min_object_covered,\n",
        "        aspect_ratio_range=aspect_ratio_range,\n",
        "        area_range=area_range,\n",
        "        max_attempts=max_attempts,\n",
        "        use_image_if_no_bounding_boxes=True)\n",
        "    bbox_begin, bbox_size, _ = sample_distorted_bounding_box\n",
        "\n",
        "    # Crop the image to the specified bounding box.\n",
        "    offset_y, offset_x, _ = tf.unstack(bbox_begin)\n",
        "    target_height, target_width, _ = tf.unstack(bbox_size)\n",
        "    image = tf.image.crop_to_bounding_box(\n",
        "        image, offset_y, offset_x, target_height, target_width)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def crop_and_resize(image, height, width):\n",
        "  \"\"\"Make a random crop and resize it to height `height` and width `width`.\n",
        "  Args:\n",
        "    image: Tensor representing the image.\n",
        "    height: Desired image height.\n",
        "    width: Desired image width.\n",
        "  Returns:\n",
        "    A `height` x `width` x channels Tensor holding a random crop of `image`.\n",
        "  \"\"\"\n",
        "  bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n",
        "  aspect_ratio = width / height\n",
        "  image = distorted_bounding_box_crop(\n",
        "      image,\n",
        "      bbox,\n",
        "      min_object_covered=0.1,\n",
        "      aspect_ratio_range=(3. / 4 * aspect_ratio, 4. / 3. * aspect_ratio),\n",
        "      area_range=(0.08, 1.0),\n",
        "      max_attempts=100,\n",
        "      scope=None)\n",
        "  return tf.image.resize_bicubic([image], [height, width])[0]\n",
        "\n",
        "\n",
        "def gaussian_blur(image, kernel_size, sigma, padding='SAME'):\n",
        "  \"\"\"Blurs the given image with separable convolution.\n",
        "  Args:\n",
        "    image: Tensor of shape [height, width, channels] and dtype float to blur.\n",
        "    kernel_size: Integer Tensor for the size of the blur kernel. This is should\n",
        "      be an odd number. If it is an even number, the actual kernel size will be\n",
        "      size + 1.\n",
        "    sigma: Sigma value for gaussian operator.\n",
        "    padding: Padding to use for the convolution. Typically 'SAME' or 'VALID'.\n",
        "  Returns:\n",
        "    A Tensor representing the blurred image.\n",
        "  \"\"\"\n",
        "  radius = tf.to_int32(kernel_size / 2)\n",
        "  kernel_size = radius * 2 + 1\n",
        "  x = tf.to_float(tf.range(-radius, radius + 1))\n",
        "  blur_filter = tf.exp(\n",
        "      -tf.pow(x, 2.0) / (2.0 * tf.pow(tf.to_float(sigma), 2.0)))\n",
        "  blur_filter /= tf.reduce_sum(blur_filter)\n",
        "  # One vertical and one horizontal filter.\n",
        "  blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
        "  blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
        "  num_channels = tf.shape(image)[-1]\n",
        "  blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
        "  blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
        "  expand_batch_dim = image.shape.ndims == 3\n",
        "  if expand_batch_dim:\n",
        "    # Tensorflow requires batched input to convolutions, which we can fake with\n",
        "    # an extra dimension.\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "  blurred = tf.nn.depthwise_conv2d(\n",
        "      image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
        "  blurred = tf.nn.depthwise_conv2d(\n",
        "      blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
        "  if expand_batch_dim:\n",
        "    blurred = tf.squeeze(blurred, axis=0)\n",
        "  return blurred\n",
        "\n",
        "\n",
        "def random_crop_with_resize(image, height, width, p=1.0):\n",
        "  \"\"\"Randomly crop and resize an image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    p: Probability of applying this transformation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  def _transform(image):  # pylint: disable=missing-docstring\n",
        "    image = crop_and_resize(image, height, width)\n",
        "    return image\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def random_color_jitter(image, p=1.0):\n",
        "  def _transform(image):\n",
        "    color_jitter_t = functools.partial(\n",
        "        color_jitter, strength=FLAGS_color_jitter_strength)\n",
        "    image = random_apply(color_jitter_t, p=0.8, x=image)\n",
        "    return random_apply(to_grayscale, p=0.2, x=image)\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def random_blur(image, height, width, p=1.0):\n",
        "  \"\"\"Randomly blur an image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    p: probability of applying this transformation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  del width\n",
        "  def _transform(image):\n",
        "    sigma = tf.random.uniform([], 0.1, 2.0, dtype=tf.float32)\n",
        "    return gaussian_blur(\n",
        "        image, kernel_size=height//10, sigma=sigma, padding='SAME')\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def batch_random_blur(images_list, height, width, blur_probability=0.5):\n",
        "  \"\"\"Apply efficient batch data transformations.\n",
        "  Args:\n",
        "    images_list: a list of image tensors.\n",
        "    height: the height of image.\n",
        "    width: the width of image.\n",
        "    blur_probability: the probaility to apply the blur operator.\n",
        "  Returns:\n",
        "    Preprocessed feature list.\n",
        "  \"\"\"\n",
        "  def generate_selector(p, bsz):\n",
        "    shape = [bsz, 1, 1, 1]\n",
        "    selector = tf.cast(\n",
        "        tf.less(tf.random_uniform(shape, 0, 1, dtype=tf.float32), p),\n",
        "        tf.float32)\n",
        "    return selector\n",
        "\n",
        "  new_images_list = []\n",
        "  for images in images_list:\n",
        "    images_new = random_blur(images, height, width, p=1.)\n",
        "    selector = generate_selector(blur_probability, tf.shape(images)[0])\n",
        "    images = images_new * selector + images * (1 - selector)\n",
        "    images = tf.clip_by_value(images, 0., 1.)\n",
        "    new_images_list.append(images)\n",
        "\n",
        "  return new_images_list\n",
        "\n",
        "\n",
        "def preprocess_for_train(image, height, width,\n",
        "                         color_distort=True, crop=True, flip=True):\n",
        "  \"\"\"Preprocesses the given image for training.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    color_distort: Whether to apply the color distortion.\n",
        "    crop: Whether to crop the image.\n",
        "    flip: Whether or not to flip left and right of an image.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  if crop:\n",
        "    image = random_crop_with_resize(image, height, width)\n",
        "  if flip:\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "  if color_distort:\n",
        "    image = random_color_jitter(image)\n",
        "  image = tf.reshape(image, [height, width, 3])\n",
        "  image = tf.clip_by_value(image, 0., 1.)\n",
        "  return image\n",
        "\n",
        "\n",
        "def preprocess_for_eval(image, height, width, crop=True):\n",
        "  \"\"\"Preprocesses the given image for evaluation.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    crop: Whether or not to (center) crop the test images.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  if crop:\n",
        "    image = center_crop(image, height, width, crop_proportion=CROP_PROPORTION)\n",
        "  image = tf.reshape(image, [height, width, 3])\n",
        "  image = tf.clip_by_value(image, 0., 1.)\n",
        "  return image\n",
        "\n",
        "\n",
        "def preprocess_image(image, height, width, is_training=False,\n",
        "                     color_distort=True, test_crop=True):\n",
        "  \"\"\"Preprocesses the given image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    is_training: `bool` for whether the preprocessing is for training.\n",
        "    color_distort: whether to apply the color distortion.\n",
        "    test_crop: whether or not to extract a central crop of the images\n",
        "        (as for standard ImageNet evaluation) during the evaluation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor` of range [0, 1].\n",
        "  \"\"\"\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  if is_training:\n",
        "    return preprocess_for_train(image, height, width, color_distort)\n",
        "  else:\n",
        "    return preprocess_for_eval(image, height, width, test_crop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "hhXTUoUs_9zd"
      },
      "outputs": [],
      "source": [
        "#@title LARS optimizer from data_util.py in SimCLR repository (hidden).\n",
        "\n",
        "EETA_DEFAULT = 0.001\n",
        "\n",
        "class LARSOptimizer(tf.train.Optimizer):\n",
        "  \"\"\"Layer-wise Adaptive Rate Scaling for large batch training.\n",
        "\n",
        "  Introduced by \"Large Batch Training of Convolutional Networks\" by Y. You,\n",
        "  I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               learning_rate,\n",
        "               momentum=0.9,\n",
        "               use_nesterov=False,\n",
        "               weight_decay=0.0,\n",
        "               exclude_from_weight_decay=None,\n",
        "               exclude_from_layer_adaptation=None,\n",
        "               classic_momentum=True,\n",
        "               eeta=EETA_DEFAULT,\n",
        "               name=\"LARSOptimizer\"):\n",
        "    \"\"\"Constructs a LARSOptimizer.\n",
        "\n",
        "    Args:\n",
        "      learning_rate: A `float` for learning rate.\n",
        "      momentum: A `float` for momentum.\n",
        "      use_nesterov: A 'Boolean' for whether to use nesterov momentum.\n",
        "      weight_decay: A `float` for weight decay.\n",
        "      exclude_from_weight_decay: A list of `string` for variable screening, if\n",
        "          any of the string appears in a variable's name, the variable will be\n",
        "          excluded for computing weight decay. For example, one could specify\n",
        "          the list like ['batch_normalization', 'bias'] to exclude BN and bias\n",
        "          from weight decay.\n",
        "      exclude_from_layer_adaptation: Similar to exclude_from_weight_decay, but\n",
        "          for layer adaptation. If it is None, it will be defaulted the same as\n",
        "          exclude_from_weight_decay.\n",
        "      classic_momentum: A `boolean` for whether to use classic (or popular)\n",
        "          momentum. The learning rate is applied during momeuntum update in\n",
        "          classic momentum, but after momentum for popular momentum.\n",
        "      eeta: A `float` for scaling of learning rate when computing trust ratio.\n",
        "      name: The name for the scope.\n",
        "    \"\"\"\n",
        "    super(LARSOptimizer, self).__init__(False, name)\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "    self.momentum = momentum\n",
        "    self.weight_decay = weight_decay\n",
        "    self.use_nesterov = use_nesterov\n",
        "    self.classic_momentum = classic_momentum\n",
        "    self.eeta = eeta\n",
        "    self.exclude_from_weight_decay = exclude_from_weight_decay\n",
        "    # exclude_from_layer_adaptation is set to exclude_from_weight_decay if the\n",
        "    # arg is None.\n",
        "    if exclude_from_layer_adaptation:\n",
        "      self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
        "    else:\n",
        "      self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
        "\n",
        "  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n",
        "    if global_step is None:\n",
        "      global_step = tf.train.get_or_create_global_step()\n",
        "    new_global_step = global_step + 1\n",
        "\n",
        "    assignments = []\n",
        "    for (grad, param) in grads_and_vars:\n",
        "      if grad is None or param is None:\n",
        "        continue\n",
        "\n",
        "      param_name = param.op.name\n",
        "\n",
        "      v = tf.get_variable(\n",
        "          name=param_name + \"/Momentum\",\n",
        "          shape=param.shape.as_list(),\n",
        "          dtype=tf.float32,\n",
        "          trainable=False,\n",
        "          initializer=tf.zeros_initializer())\n",
        "\n",
        "      if self._use_weight_decay(param_name):\n",
        "        grad += self.weight_decay * param\n",
        "\n",
        "      if self.classic_momentum:\n",
        "        trust_ratio = 1.0\n",
        "        if self._do_layer_adaptation(param_name):\n",
        "          w_norm = tf.norm(param, ord=2)\n",
        "          g_norm = tf.norm(grad, ord=2)\n",
        "          trust_ratio = tf.where(\n",
        "              tf.greater(w_norm, 0), tf.where(\n",
        "                  tf.greater(g_norm, 0), (self.eeta * w_norm / g_norm),\n",
        "                  1.0),\n",
        "              1.0)\n",
        "        scaled_lr = self.learning_rate * trust_ratio\n",
        "\n",
        "        next_v = tf.multiply(self.momentum, v) + scaled_lr * grad\n",
        "        if self.use_nesterov:\n",
        "          update = tf.multiply(self.momentum, next_v) + scaled_lr * grad\n",
        "        else:\n",
        "          update = next_v\n",
        "        next_param = param - update\n",
        "      else:\n",
        "        next_v = tf.multiply(self.momentum, v) + grad\n",
        "        if self.use_nesterov:\n",
        "          update = tf.multiply(self.momentum, next_v) + grad\n",
        "        else:\n",
        "          update = next_v\n",
        "\n",
        "        trust_ratio = 1.0\n",
        "        if self._do_layer_adaptation(param_name):\n",
        "          w_norm = tf.norm(param, ord=2)\n",
        "          v_norm = tf.norm(update, ord=2)\n",
        "          trust_ratio = tf.where(\n",
        "              tf.greater(w_norm, 0), tf.where(\n",
        "                  tf.greater(v_norm, 0), (self.eeta * w_norm / v_norm),\n",
        "                  1.0),\n",
        "              1.0)\n",
        "        scaled_lr = trust_ratio * self.learning_rate\n",
        "        next_param = param - scaled_lr * update\n",
        "\n",
        "      assignments.extend(\n",
        "          [param.assign(next_param),\n",
        "           v.assign(next_v),\n",
        "           global_step.assign(new_global_step)])\n",
        "    return tf.group(*assignments, name=name)\n",
        "\n",
        "  def _use_weight_decay(self, param_name):\n",
        "    \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n",
        "    if not self.weight_decay:\n",
        "      return False\n",
        "    if self.exclude_from_weight_decay:\n",
        "      for r in self.exclude_from_weight_decay:\n",
        "        if re.search(r, param_name) is not None:\n",
        "          return False\n",
        "    return True\n",
        "\n",
        "  def _do_layer_adaptation(self, param_name):\n",
        "    \"\"\"Whether to do layer-wise learning rate adaptation for `param_name`.\"\"\"\n",
        "    if self.exclude_from_layer_adaptation:\n",
        "      for r in self.exclude_from_layer_adaptation:\n",
        "        if re.search(r, param_name) is not None:\n",
        "          return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 17/2766 [00:00<00:49, 55.17it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2766/2766 [00:29<00:00, 93.11it/s] \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Example lists of file paths and labels\n",
        "image_paths = list(os.listdir(\"data/DAM\"))\n",
        "labels = [mmc_to_int[image_path.split(\".\")[0]] for image_path in image_paths]\n",
        "\n",
        "images = list()\n",
        "\n",
        "for image_path in tqdm(image_paths):\n",
        "    images.append(np.array(Image.open('data/DAM/'+image_path)))\n",
        "\n",
        "images_tensor = tf.convert_to_tensor(images)\n",
        "labels_tensor = tf.convert_to_tensor(labels)\n",
        "\n",
        "# # Create a dataset from the image paths and labels\n",
        "dataset = tf.data.Dataset.from_tensor_slices({'image': images_tensor, 'label': labels_tensor})\n",
        "\n",
        "# # Optional: Shuffle and batch the dataset\n",
        "# dataset = dataset.shuffle(buffer_size=len(image_paths)).batch(batch_size)\n",
        "\n",
        "# # Print the first few elements of the dataset\n",
        "# for image, label in dataset.take(2):\n",
        "#     print(\"Image shape:\", image.shape)\n",
        "#     print(\"Label:\", label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2766, 256, 256, 3), dtype=int32, numpy=\n",
              "array([[[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]]])>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Shuffle and batch the dataset\n",
        "dataset = dataset.shuffle(buffer_size=len(image_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'image': array([[[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         ...,\n",
              "         [2, 2, 2],\n",
              "         [2, 2, 2],\n",
              "         [2, 2, 2]],\n",
              " \n",
              "        [[1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         ...,\n",
              "         [2, 2, 2],\n",
              "         [2, 2, 2],\n",
              "         [2, 2, 2]],\n",
              " \n",
              "        [[1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         [1, 1, 1],\n",
              "         ...,\n",
              "         [2, 2, 2],\n",
              "         [2, 2, 2],\n",
              "         [2, 2, 2]]]),\n",
              " 'label': 1655}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(dataset.as_numpy_iterator())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "2868bb86328140c8b57261bc7553a493",
            "478d81aa7b40453087d9af9f4a369da2",
            "93fdbea71c5c4fb584e4f2f7dbee1095",
            "44873aa666604643ba00f7f10b2f23f5",
            "eebdb001d1c440feb9f29d306a01c6f1",
            "0c291ed1e43945b191bac0a146ca5535",
            "5ac89e4187f7412494411393688b54ac",
            "e0299bb4c2834266a5f0eb10c2061306",
            "1338b9cfcd38472c9fc843489b4c29e9",
            "7026ef7375cc4187afb18e53740d62e7",
            "089cc40f1f2b4b2ea149d4746c7f245e"
          ]
        },
        "id": "MDCY4h7bHxj8",
        "outputId": "a0a572b3-1882-45e7-d6af-4407adeada00"
      },
      "outputs": [],
      "source": [
        "#@title Load tensorflow datasets: we use tensorflow flower dataset as an example\n",
        "\n",
        "batch_size = 64\n",
        "dataset_name = 'tf_flowers'\n",
        "\n",
        "# tfds_dataset, tfds_info = tfds.load(\n",
        "#     dataset_name, split='train', with_info=True)\n",
        "# num_images = tfds_info.splits['train'].num_examples\n",
        "# num_classes = tfds_info.features['label'].num_classes\n",
        "\n",
        "\n",
        "\n",
        "def _preprocess(x):\n",
        "  x['image'] = preprocess_image(\n",
        "      x['image'], 224, 224, is_training=False, color_distort=False)\n",
        "  return x\n",
        "x = dataset.map(_preprocess).batch(batch_size)\n",
        "x = tf.data.make_one_shot_iterator(x).get_next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = len(mmc_to_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2767"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-io in c:\\python310\\lib\\site-packages (0.31.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in c:\\python310\\lib\\site-packages (from tensorflow-io) (0.31.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow-io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_io as tfio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Version:  2.9.1\n"
          ]
        }
      ],
      "source": [
        "print(\"Version: \", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WXspghpERRG",
        "outputId": "007485a4-5427-439a-e259-236ff41f42d6"
      },
      "outputs": [
        {
          "ename": "UnimplementedError",
          "evalue": "File system scheme 'gs' not implemented (file: 'gs://simclr-checkpoints/simclrv2/finetuned_100pct/r50_1x_sk0/hub/')",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\User\\Desktop\\sapkomjamain\\finetuning_simCLR.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m hub_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgs://simclr-checkpoints/simclrv2/finetuned_100pct/r50_1x_sk0/hub/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# module = hub.Module(tfio.IOTensor.from_s3(hub_path), trainable=False)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m gcs_module_path \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mGFile(hub_path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m module \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mModule(gcs_module_path, trainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m key \u001b[39m=\u001b[39m module(inputs\u001b[39m=\u001b[39mx[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m], signature\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m, as_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:114\u001b[0m, in \u001b[0;36mFileIO.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    103\u001b[0m   \u001b[39m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[0;32m    105\u001b[0m \u001b[39m  Starts reading from current position in file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m    string if in string (regular) mode.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preread_check()\n\u001b[0;32m    115\u001b[0m   \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    116\u001b[0m     length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:76\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_check_passed:\n\u001b[0;32m     74\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mPermissionDeniedError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m                                      \u001b[39m\"\u001b[39m\u001b[39mFile isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt open for reading\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_buf \u001b[39m=\u001b[39m _pywrap_file_io\u001b[39m.\u001b[39;49mBufferedInputStream(\n\u001b[0;32m     77\u001b[0m     compat\u001b[39m.\u001b[39;49mpath_to_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name), \u001b[39m1024\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m512\u001b[39;49m)\n",
            "\u001b[1;31mUnimplementedError\u001b[0m: File system scheme 'gs' not implemented (file: 'gs://simclr-checkpoints/simclrv2/finetuned_100pct/r50_1x_sk0/hub/')"
          ]
        }
      ],
      "source": [
        "#@title Load module and construct the computation graph\n",
        "\n",
        "learning_rate = 0.1\n",
        "momentum = 0.9\n",
        "weight_decay = 0.\n",
        "\n",
        "# Load the base network and set it to non-trainable (for speedup fine-tuning)\n",
        "hub_path = 'gs://simclr-checkpoints/simclrv2/finetuned_100pct/r50_1x_sk0/hub/'\n",
        "# module = hub.Module(tfio.IOTensor.from_s3(hub_path), trainable=False)\n",
        "\n",
        "gcs_module_path = tf.io.gfile.GFile(hub_path, 'rb').read()\n",
        "module = hub.Module(gcs_module_path, trainable=False)\n",
        "\n",
        "key = module(inputs=x['image'], signature=\"default\", as_dict=True)\n",
        "\n",
        "# Attach a trainable linear layer to adapt for the new task.\n",
        "with tf.variable_scope('head_supervised_new', reuse=tf.AUTO_REUSE):\n",
        "  logits_t = tf.layers.dense(inputs=key['final_avg_pool'], units=num_classes)\n",
        "loss_t = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "    labels=tf.one_hot(x['label'], num_classes), logits=logits_t))\n",
        "\n",
        "# Setup optimizer and training op.\n",
        "optimizer = LARSOptimizer(\n",
        "    learning_rate,\n",
        "    momentum=momentum,\n",
        "    weight_decay=weight_decay,\n",
        "    exclude_from_weight_decay=['batch_normalization', 'bias', 'head_supervised'])\n",
        "variables_to_train = tf.trainable_variables()\n",
        "train_op = optimizer.minimize(\n",
        "    loss_t, global_step=tf.train.get_or_create_global_step(),\n",
        "    var_list=variables_to_train)\n",
        "\n",
        "print('Variables to train:', variables_to_train)\n",
        "key # The accessible tensor in the return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XHj1FZ2dEXIj"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The Session graph is empty. Add operations to the graph before calling run().",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\User\\Desktop\\sapkomjamain\\finetuning_simCLR.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sess \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mSession()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sess\u001b[39m.\u001b[39;49mrun(tf\u001b[39m.\u001b[39;49mglobal_variables_initializer())\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    964\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    968\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    970\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\client\\session.py:1117\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1115\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempted to use a closed Session.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mversion \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1117\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe Session graph is empty. Add operations to the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1118\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mgraph before calling run().\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1120\u001b[0m \u001b[39m# Create request.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m feed_dict_tensor \u001b[39m=\u001b[39m {}\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The Session graph is empty. Add operations to the graph before calling run()."
          ]
        }
      ],
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "HHSQuEwnCBKN",
        "outputId": "c66a6eb3-e19d-46f6-d384-5979c8eb0d87"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'sess' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\User\\Desktop\\sapkomjamain\\finetuning_simCLR.ipynb Cell 26\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m total_iterations \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(total_iterations):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   _, loss, image, logits, labels \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mrun((train_op, loss_t, x[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m], logits_t, x[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   pred \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39margmax(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/sapkomjamain/finetuning_simCLR.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   correct \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(pred \u001b[39m==\u001b[39m labels)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
          ]
        }
      ],
      "source": [
        "#@title We fine-tune the new *linear layer* for just a few iterations.\n",
        "\n",
        "total_iterations = 10\n",
        "\n",
        "for it in range(total_iterations):\n",
        "  _, loss, image, logits, labels = sess.run((train_op, loss_t, x['image'], logits_t, x['label']))\n",
        "  pred = logits.argmax(-1)\n",
        "  correct = np.sum(pred == labels)\n",
        "  total = labels.size\n",
        "  print(\"[Iter {}] Loss: {} Top 1: {}\".format(it+1, loss, correct/float(total)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOhK8anzK21K"
      },
      "outputs": [],
      "source": [
        "#@title Plot the images and predictions\n",
        "fig, axes = plt.subplots(5, 1, figsize=(15, 15))\n",
        "for i in range(5):\n",
        "  axes[i].imshow(image[i])\n",
        "  true_text = tf_flowers_labels[labels[i]]\n",
        "  pred_text = tf_flowers_labels[pred[i]]\n",
        "  axes[i].axis('off')\n",
        "  axes[i].text(256, 128, 'Truth: ' + true_text + '\\n' + 'Pred: ' + pred_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "finetuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "089cc40f1f2b4b2ea149d4746c7f245e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c291ed1e43945b191bac0a146ca5535": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1338b9cfcd38472c9fc843489b4c29e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2868bb86328140c8b57261bc7553a493": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_478d81aa7b40453087d9af9f4a369da2",
              "IPY_MODEL_93fdbea71c5c4fb584e4f2f7dbee1095",
              "IPY_MODEL_44873aa666604643ba00f7f10b2f23f5"
            ],
            "layout": "IPY_MODEL_eebdb001d1c440feb9f29d306a01c6f1"
          }
        },
        "44873aa666604643ba00f7f10b2f23f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7026ef7375cc4187afb18e53740d62e7",
            "placeholder": "​",
            "style": "IPY_MODEL_089cc40f1f2b4b2ea149d4746c7f245e",
            "value": " 5/5 [00:02&lt;00:00,  2.43 file/s]"
          }
        },
        "478d81aa7b40453087d9af9f4a369da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c291ed1e43945b191bac0a146ca5535",
            "placeholder": "​",
            "style": "IPY_MODEL_5ac89e4187f7412494411393688b54ac",
            "value": "Dl Completed...: 100%"
          }
        },
        "5ac89e4187f7412494411393688b54ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7026ef7375cc4187afb18e53740d62e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93fdbea71c5c4fb584e4f2f7dbee1095": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0299bb4c2834266a5f0eb10c2061306",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1338b9cfcd38472c9fc843489b4c29e9",
            "value": 5
          }
        },
        "e0299bb4c2834266a5f0eb10c2061306": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eebdb001d1c440feb9f29d306a01c6f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
